version: '3.8'
services:
  owasp-llm-demo:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: owasp-llm-security-demo
    ports:
      - "3000:3000"  # Frontend
      - "5000:5000"  # API
      - "8081:8081"  # llama-server
    environment:
      - FLASK_ENV=production
      - NODE_ENV=production
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '12.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 1G

